# Task3
> 线性回归

## 如何运行

### Requirements

- python package:

  ```
  numpy
  matplotlib
  ```

- python version: python > 3.5

### Shell

在源代码目录下运行 `python main.py` 即可

## 梯度下降

梯度下降对每个样本（batch）的数据计算平方误差，然后通过梯度法则计算到各个参数对应的需要更新的值。

## 最小二乘

最小二乘法一次输入全部数据，通过正规方程计算得到参数的值

## 结果

人工设置随机种子 `seed=43`，通过 `random.seed()` 和 `numpy.random.seed()` 方法设置随机种子以确保可复现性。

### 梯度下降结果

设置 `learning rate=0.01` `max epoch=1000`，迭代 1000 轮后，误差为 $0.19372796783688342$，计算得到的权重为 $w=-0.19269696$ $b=-0.30885399$

### 最小二乘结果

正规方程的拟合误差为 $0.19372796741230697$，拟合得到的权重参数是 $w=-0.19270003$ $b=-0.30888415$

### 对比

可以看到，最小二乘的误差略小于梯度下降的误差。这是因为正规方程是通过导数理论计算求得极值点进而算出最优的参数，而梯度下降则是通过迭代，每次计算损失函数进行梯度更新，这样只能保证求得相对的最优解。

同时，相比梯度计算需要迭代多次，正规方程只需要对全体数据进行一次计算即可，在数据较大时能够取得更好的结果。

### 多项回归

我们设置最多项式最高次为 `3`，也即原始的回归方程可以写为 $y=w_1x^3+w_2x^2+w_3x+b$。通过多元最小二乘法计算得到参数分别为 $\boldsymbol W=[-0.03046776, -0.08538946, 0.09468246], b=0.09803738$

此时残差为 $0.06917839140681437$
